{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Exercise 2: Basic Statisics"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Task 1: Data Analysis with Pandas\n",
    "Make sure you installed the pandas package. Download the Iris Plant Dataset from the UCI Machine Learning Repository:\n",
    "https://archive.ics.uci.edu/ml/datasets/Iris\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### a) Preprocessing and Descriptive Statistics"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Read the Iris dataset into a pandas dataframe. Note that you will need to name the columns yourself according to the _attribute information_ on the UCI website above. Print the dataframe and make sure your dataframe has 150 rows."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sepal_length</th>\n",
       "      <th>sepal_width</th>\n",
       "      <th>petal_weight</th>\n",
       "      <th>petal_width</th>\n",
       "      <th>class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>5.1</td>\n",
       "      <td>3.5</td>\n",
       "      <td>1.4</td>\n",
       "      <td>0.2</td>\n",
       "      <td>Iris-setosa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>4.9</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.4</td>\n",
       "      <td>0.2</td>\n",
       "      <td>Iris-setosa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>4.7</td>\n",
       "      <td>3.2</td>\n",
       "      <td>1.3</td>\n",
       "      <td>0.2</td>\n",
       "      <td>Iris-setosa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>4.6</td>\n",
       "      <td>3.1</td>\n",
       "      <td>1.5</td>\n",
       "      <td>0.2</td>\n",
       "      <td>Iris-setosa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>5.0</td>\n",
       "      <td>3.6</td>\n",
       "      <td>1.4</td>\n",
       "      <td>0.2</td>\n",
       "      <td>Iris-setosa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>145</td>\n",
       "      <td>6.7</td>\n",
       "      <td>3.0</td>\n",
       "      <td>5.2</td>\n",
       "      <td>2.3</td>\n",
       "      <td>Iris-virginica</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>146</td>\n",
       "      <td>6.3</td>\n",
       "      <td>2.5</td>\n",
       "      <td>5.0</td>\n",
       "      <td>1.9</td>\n",
       "      <td>Iris-virginica</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>147</td>\n",
       "      <td>6.5</td>\n",
       "      <td>3.0</td>\n",
       "      <td>5.2</td>\n",
       "      <td>2.0</td>\n",
       "      <td>Iris-virginica</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>148</td>\n",
       "      <td>6.2</td>\n",
       "      <td>3.4</td>\n",
       "      <td>5.4</td>\n",
       "      <td>2.3</td>\n",
       "      <td>Iris-virginica</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>149</td>\n",
       "      <td>5.9</td>\n",
       "      <td>3.0</td>\n",
       "      <td>5.1</td>\n",
       "      <td>1.8</td>\n",
       "      <td>Iris-virginica</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>150 rows Ã— 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     sepal_length  sepal_width   petal_weight  petal_width           class\n",
       "0             5.1          3.5            1.4          0.2     Iris-setosa\n",
       "1             4.9          3.0            1.4          0.2     Iris-setosa\n",
       "2             4.7          3.2            1.3          0.2     Iris-setosa\n",
       "3             4.6          3.1            1.5          0.2     Iris-setosa\n",
       "4             5.0          3.6            1.4          0.2     Iris-setosa\n",
       "..            ...          ...            ...          ...             ...\n",
       "145           6.7          3.0            5.2          2.3  Iris-virginica\n",
       "146           6.3          2.5            5.0          1.9  Iris-virginica\n",
       "147           6.5          3.0            5.2          2.0  Iris-virginica\n",
       "148           6.2          3.4            5.4          2.3  Iris-virginica\n",
       "149           5.9          3.0            5.1          1.8  Iris-virginica\n",
       "\n",
       "[150 rows x 5 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv(\"iris.data\", names = [\"sepal_length\", \"sepal_width\",\" petal_weight\", \"petal_width\", \"class\"])\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Use pandas built-in functions to compute the mean, variance, minimum and maximum of the _sepal length_ of all plants in the datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5.843333333333334\n",
      "0.6856935123042507\n",
      "4.3\n",
      "7.9\n"
     ]
    }
   ],
   "source": [
    "print(df.sepal_length.mean())\n",
    "print(df.sepal_length.var())\n",
    "print(df.loc[:,\"sepal_length\"].min())\n",
    "print(df.loc[:,\"sepal_length\"].max())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Write a function that takes a (numerical) column of a pandas dataframe as input and computes its median. Use it to compute the median of the _petal width_ and compare it to the output of pandas built-in median function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.3\n",
      "1.3\n"
     ]
    }
   ],
   "source": [
    "def median(col):\n",
    "    m_ind = int((len(col)-1)/2)\n",
    "    # convert to numpy to avoid hassle with panda index\n",
    "    col = col.to_numpy()\n",
    "    col.sort()\n",
    "    return col[m_ind]\n",
    "    \n",
    "print(median(df.loc[:,\"petal_width\"]))\n",
    "print(df.petal_width.median())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### b) Pearson's Correlation Coefficient"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Write a function that takes two (numerical) pandas columns as input and returns their Pearson correlation coefficient. Do not use any pandas/numpy/scipy built-ins."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def pearson(x, y):\n",
    "    n = len(x)\n",
    "    x_hat, y_hat = sum(x)/n, sum(y)/n\n",
    "    dx, dy = [v-x_hat for v in x], [v-y_hat for v in y]\n",
    "    s_x, s_y = (sum(d**2 for d in dx)/n)**.5, (sum(d**2 for d in dy)/n)**.5\n",
    "    \n",
    "    return sum(dx[i]*dy[i]/n for i in range(n))/(s_x*s_y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Apply your function to compute the correlation between _sepal length_ and _sepal width_. Check it for correctness by applying the corresponding scipy built-in. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-0.10936924995064931\n",
      "(-0.10936924995064934, 0.1827652152713699)\n"
     ]
    }
   ],
   "source": [
    "from scipy.stats import pearsonr\n",
    "\n",
    "print(pearson(df.sepal_length,df.sepal_width))\n",
    "print(pearsonr(df.sepal_length,df.sepal_width))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### c) Hypothesis Testing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Compute the mean _sepal width_ for all plants that are classed as _Iris-versicolor_ and for all plants that are classed as _Iris-virginica_ ."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.7700000000000005\n",
      "2.974\n"
     ]
    }
   ],
   "source": [
    "mean_setosa = df.loc[df.loc[:,\"class\"] == \"Iris-versicolor\"].sepal_width.mean()\n",
    "mean_virginica = df.loc[df.loc[:,\"class\"] == \"Iris-virginica\"].sepal_width.mean()\n",
    "\n",
    "\n",
    "print(mean_setosa)\n",
    "print(mean_virginica)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Consider the null hypothesis that there is no difference in the means of the groups. Compute the corresponding _p_-value by shuffling the class labels 100000 times and computing the difference in means each of these times. Do you oberve a significant difference?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-0.20399999999999974\n",
      "<class 'numpy.ndarray'>\n",
      "Empirical p-value: 0.0086\n"
     ]
    }
   ],
   "source": [
    "mean_diff = mean_setosa-mean_virginica\n",
    "print(mean_diff)\n",
    "\n",
    "col = df.loc[df.loc[:,\"class\"] != \"Iris-setosa\",\"sepal_width\"].to_numpy()\n",
    "print(type(col))\n",
    "ct = 0\n",
    "for i in range(100000):\n",
    "    np.random.shuffle(col)\n",
    "    diff = np.mean(col[:50]) - np.mean(col[50:])\n",
    "    if diff < mean_diff:\n",
    "        ct+=1\n",
    "p_value = ct/10000\n",
    "print(\"Empirical p-value: \" + str(p_value))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### d) The Bootstrap\n",
    "\n",
    "We consider the _sepal width_ of all plants in the data that are classed as _Iris-setosa_. Compute the 95% confidence interval of their mean by bootstrapping the data 10000 times. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3.418\n",
      "Confidence interval: (3.316,3.5239999999999996)\n"
     ]
    }
   ],
   "source": [
    "from random import choices\n",
    "sw = df.loc[df.loc[:,\"class\"] == \"Iris-setosa\",\"sepal_width\"].to_numpy()\n",
    "print(np.mean(sw))\n",
    "means = []\n",
    "for i in range(10000):\n",
    "    sample = sw[choices(range(50), k=50)]\n",
    "    means.append(np.mean(sample))\n",
    "    \n",
    "means = np.sort(means)\n",
    "print(\"Confidence interval: (\" + str(means[249]) +\",\"+ str(means[9749]) + \")\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Task 2: A Dice Game"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Consider the following game of dices: You roll 5 dice, and you get points for each die you roll.\n",
    "For each one, you get 100 points, for each six, you get 60 points, for all other numbers just the shown value (e.g., you get 3 points for a 3). Your total score is the sum of these points."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### a) Simulation and Plotting\n",
    "\n",
    "Simulate the game 100,000 times, and save both every single dice roll as well as the resulting score for each of the 100000 rounds. Plot a histogram of outcomes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[323, 73, 460, 114, 266, 166, 170, 74, 14, 115]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scores = np.array([0,100,2,3,4,5,60])\n",
    "def score_roll(roll):\n",
    "    return np.sum(scores[roll])\n",
    "\n",
    "\n",
    "#roll 100,000 times and store the results in an array\n",
    "rolls = [choices(range(1,7),k=5) for _ in range(100000)]\n",
    "scores = [score_roll(roll) for roll in rolls]\n",
    "\n",
    "scores[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([1.5400e+03, 8.6540e+03, 2.8670e+03, 1.5000e+01, 0.0000e+00,\n",
       "        0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
       "        0.0000e+00, 7.2000e+01, 6.8780e+03, 9.2300e+03, 3.8600e+02,\n",
       "        0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
       "        4.2820e+03, 1.1257e+04, 9.7800e+02, 5.0500e+02, 6.4260e+03,\n",
       "        1.2900e+03, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
       "        0.0000e+00, 2.6000e+02, 1.0852e+04, 5.1960e+03, 0.0000e+00,\n",
       "        8.0500e+02, 1.3220e+03, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
       "        4.2220e+03, 4.0860e+03, 0.0000e+00, 1.1880e+03, 5.0620e+03,\n",
       "        0.0000e+00, 0.0000e+00, 2.6800e+02, 0.0000e+00, 0.0000e+00,\n",
       "        0.0000e+00, 3.6200e+02, 5.3340e+03, 3.7100e+02, 0.0000e+00,\n",
       "        7.5300e+02, 2.1600e+02, 0.0000e+00, 0.0000e+00, 1.8000e+01,\n",
       "        1.7150e+03, 3.8000e+02, 0.0000e+00, 7.1700e+02, 8.2000e+02,\n",
       "        0.0000e+00, 0.0000e+00, 6.6000e+01, 0.0000e+00, 0.0000e+00,\n",
       "        0.0000e+00, 2.7400e+02, 7.5900e+02, 0.0000e+00, 0.0000e+00,\n",
       "        1.2800e+02, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
       "        2.3300e+02, 0.0000e+00, 0.0000e+00, 1.3300e+02, 0.0000e+00,\n",
       "        0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
       "        0.0000e+00, 6.9000e+01, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
       "        0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 1.1000e+01]),\n",
       " array([ 10. ,  14.9,  19.8,  24.7,  29.6,  34.5,  39.4,  44.3,  49.2,\n",
       "         54.1,  59. ,  63.9,  68.8,  73.7,  78.6,  83.5,  88.4,  93.3,\n",
       "         98.2, 103.1, 108. , 112.9, 117.8, 122.7, 127.6, 132.5, 137.4,\n",
       "        142.3, 147.2, 152.1, 157. , 161.9, 166.8, 171.7, 176.6, 181.5,\n",
       "        186.4, 191.3, 196.2, 201.1, 206. , 210.9, 215.8, 220.7, 225.6,\n",
       "        230.5, 235.4, 240.3, 245.2, 250.1, 255. , 259.9, 264.8, 269.7,\n",
       "        274.6, 279.5, 284.4, 289.3, 294.2, 299.1, 304. , 308.9, 313.8,\n",
       "        318.7, 323.6, 328.5, 333.4, 338.3, 343.2, 348.1, 353. , 357.9,\n",
       "        362.8, 367.7, 372.6, 377.5, 382.4, 387.3, 392.2, 397.1, 402. ,\n",
       "        406.9, 411.8, 416.7, 421.6, 426.5, 431.4, 436.3, 441.2, 446.1,\n",
       "        451. , 455.9, 460.8, 465.7, 470.6, 475.5, 480.4, 485.3, 490.2,\n",
       "        495.1, 500. ]),\n",
       " <a list of 100 Patch objects>)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# use matplotlib/pyplot\n",
    "from matplotlib import pyplot as plt\n",
    "%matplotlib inline\n",
    "plt.hist (scores, bins=100, edgecolor='black')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### b) Hypothesis Testing pt. 2\n",
    "Assume that in your initial roll, you scored 268. Is this signficantly above what is to be expected? Compute the corresponding _p_-value."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.0859\n"
     ]
    }
   ],
   "source": [
    "p_value = np.sum([1 for x in scores if x >= 268]) / len(scores)\n",
    "print(p_value) # p>0.05, thus no significant effect"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### c) Conditional Probability and Bayes Theorem\n",
    "\n",
    "Based on your simulation, give an estimation of the probability of scoring over 100 points, given that you did not roll a single 1."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "P(score>100|no 1 rolled) = 0.02640282053828583\n"
     ]
    }
   ],
   "source": [
    "# probability of scoring over 150 points without rolling a 1\n",
    "p1 = sum(1 if scores[i] > 100 and 1 not in rolls[i] else 0 for i in range(100000))/100000\n",
    "\n",
    "# probability of not rolling a 1\n",
    "p2 = sum(1 if 1 not in roll else 0 for roll in rolls)/10000\n",
    "\n",
    "p_cond = p1/p2\n",
    "\n",
    "print(\"P(score>100|no 1 rolled) = \" + str(p_cond))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now estimate the probability of scoring over 100 points, and apply your previous results and Bayes Theorem to compute the probability of not rolling a 1 given that you score over 100 points."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "P(no 1 rolled | score>100) = 0.1511413058927201\n"
     ]
    }
   ],
   "source": [
    "p3 = sum(1 if score > 100 else 0 for score in scores)/100000\n",
    "\n",
    "print(\"P(no 1 rolled | score>100) = \" + str(p_cond*p2/p3))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
