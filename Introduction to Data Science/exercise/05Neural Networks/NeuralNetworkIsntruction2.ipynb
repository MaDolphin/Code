{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Simple Neural Nework\n",
    "Here we try to write a simple neural network to understand how backpropagation algorithm works :)\n",
    "## Now we create a simple one layer newtork "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Continue our feedforward network and make it a complete neural network that can predict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "dot() missing 1 required positional argument: 'b'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-3-c07dd2828541>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     48\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m100\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     49\u001b[0m         \u001b[0mnn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfeedforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 50\u001b[0;31m         \u001b[0mnn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackprop\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     51\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     52\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mweights1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-3-c07dd2828541>\u001b[0m in \u001b[0;36mbackprop\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m     28\u001b[0m         \u001b[0;31m# application of the chain rule to find derivative of the Error with respect to weights2 and weights1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     29\u001b[0m         \u001b[0md_weights2\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlayer1\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mT\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0my\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moutput\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0msigmoid_derivative\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moutput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 30\u001b[0;31m         \u001b[0md_weights1\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mT\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0my\u001b[0m \u001b[0;34m-\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moutput\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0msigmoid_derivative\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moutput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mweights2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     31\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     32\u001b[0m         \u001b[0;31m# update the weights with the derivative (slope) of the loss function\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<__array_function__ internals>\u001b[0m in \u001b[0;36mdot\u001b[0;34m(*args, **kwargs)\u001b[0m\n",
      "\u001b[0;31mTypeError\u001b[0m: dot() missing 1 required positional argument: 'b'"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "\n",
    "#activation funcion\n",
    "def sigmoid(x):\n",
    "    return 1.0/(1 + np.exp(-x))\n",
    "\n",
    "#deivative of activation funcion\n",
    "def sigmoid_derivative(x):\n",
    "    return x * (1.0 - x)\n",
    "\n",
    "#class of your neural network\n",
    "class NeuralNetwork:\n",
    "    \n",
    "    #set features of your neural network\n",
    "    def __init__(self, x, y):\n",
    "        self.input      = x\n",
    "        self.weights1   = np.random.rand(self.input.shape[1],2)\n",
    "        self.weights2   = np.random.rand(2,1)              \n",
    "        self.y          = y\n",
    "        self.output     = np.zeros(self.y.shape)\n",
    "    #feedfarward function \n",
    "    def feedforward(self):\n",
    "        self.layer1 = sigmoid(np.dot(self.input, self.weights1))\n",
    "        self.output = sigmoid(np.dot(self.layer1, self.weights2))\n",
    "    #backpropagate the error\n",
    "    def backprop(self):\n",
    "        # application of the chain rule to find derivative of the Error with respect to weights2 and weights1\n",
    "        d_weights2 = np.dot(self.layer1.T, ((self.y - self.output) * sigmoid_derivative(self.output)))\n",
    "        d_weights1 = np.dot(self.input.T, (np.dot(self.y -self.output) * sigmoid_derivative(self.output), self.weights2))\n",
    "\n",
    "        # update the weights with the derivative (slope) of the loss function\n",
    "        self.weights1 = self.weights1 + d_weights1\n",
    "        self.weights2 = self.weights2 + d_weights2\n",
    "\n",
    "#Test what you have done :D \n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    X = np.array([[0,0,1],\n",
    "                  [0,1,1],\n",
    "                  [1,0,1],\n",
    "                  [1,1,1]])\n",
    "    y = np.array([[0],[1],[1],[0]])\n",
    "   \n",
    "    nn = NeuralNetwork(X,y)\n",
    "   \n",
    "    #do the iteration for learning\n",
    "    for i in range(100):\n",
    "        nn.feedforward()\n",
    "        nn.backprop()\n",
    "   \n",
    "    print(nn.weights1)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Python Useful Libraries\n",
    "Simple Example!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/hhk/anaconda3/lib/python3.7/site-packages/sklearn/neural_network/multilayer_perceptron.py:921: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/Users/hhk/anaconda3/lib/python3.7/site-packages/sklearn/neural_network/multilayer_perceptron.py:566: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "MLPClassifier(activation='relu', alpha=0.0001, batch_size='auto', beta_1=0.9,\n",
       "              beta_2=0.999, early_stopping=False, epsilon=1e-08,\n",
       "              hidden_layer_sizes=(100,), learning_rate='constant',\n",
       "              learning_rate_init=0.001, max_iter=200, momentum=0.9,\n",
       "              n_iter_no_change=10, nesterovs_momentum=True, power_t=0.5,\n",
       "              random_state=None, shuffle=True, solver='adam', tol=0.0001,\n",
       "              validation_fraction=0.1, verbose=False, warm_start=False)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.neural_network import MLPClassifier\n",
    "X = [[0, 0], [1, 1]]\n",
    "y = [[0], [1]]\n",
    "clf = MLPClassifier()\n",
    "clf.fit(X, y)                         \n",
    "# clf.predict([[1, 2]])\n",
    "# clf.predict([[0, 0]])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## OR Function\n",
    "Let us start with a simple example of Boolean OR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/hhk/anaconda3/lib/python3.7/site-packages/sklearn/neural_network/multilayer_perceptron.py:566: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([1])"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.linear_model import Perceptron\n",
    "import sklearn.metrics as metric\n",
    "import numpy as np\n",
    "\n",
    "X_training=[[0, 0], \n",
    "            [0, 1],\n",
    "            [1, 0],\n",
    "            [1, 1]]\n",
    "y_training=[0,\n",
    "            1,\n",
    "            1,\n",
    "            1]\n",
    "\n",
    "mlp = MLPClassifier()\n",
    "mlp.fit(X_training, y_training)\n",
    "mlp.predict([[1,1]])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Multi-Layer Networks\n",
    "\n",
    "The following code is the example of how you will use Multi-Layer Perceptron (MLP) Neural Network to train, predict. You can also get the weights of the Neural Network.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0 1 1 1]\n",
      "[(2, 100), (100, 1)]\n",
      "[array([[ 1.53104942e-01, -2.43784015e-02, -1.30414243e-04,\n",
      "         6.65434432e-02, -3.01425206e-01,  4.65720925e-01,\n",
      "         2.77783946e-02,  1.10115446e-01,  2.63633984e-01,\n",
      "        -1.94573704e-01,  2.92034320e-01,  7.59461754e-02,\n",
      "         1.85756515e-01,  8.19998498e-02,  2.96180722e-01,\n",
      "         1.53618835e-02,  1.22642672e-01,  2.26552196e-01,\n",
      "        -2.14830318e-01, -4.28881850e-08, -1.14049316e-02,\n",
      "        -1.70603739e-01, -2.80466409e-04,  1.89060779e-01,\n",
      "        -3.33744535e-02,  1.19018733e-01,  2.22619894e-05,\n",
      "         5.18891662e-02,  1.25385717e-07,  2.21440982e-01,\n",
      "        -1.70458178e-02, -6.16695069e-02,  3.58273535e-01,\n",
      "        -2.81257612e-02,  1.40240284e-01, -6.68021497e-04,\n",
      "        -1.32479053e-01,  3.02933209e-01,  8.63429910e-02,\n",
      "        -1.08668084e-02,  2.94138476e-01,  2.25529698e-01,\n",
      "        -6.85888416e-03, -1.40183609e-01, -9.20861238e-03,\n",
      "         4.18418257e-03,  6.96178089e-02,  7.18726561e-02,\n",
      "        -2.19737598e-03, -6.68607548e-03,  1.70241494e-01,\n",
      "         2.55624430e-01,  5.29986482e-06,  1.51756492e-01,\n",
      "         1.02846537e-02, -1.70075496e-02, -9.45044704e-08,\n",
      "         7.59395790e-02, -3.16378580e-01,  6.66216777e-03,\n",
      "        -1.64273186e-01,  5.99555162e-03, -6.69677445e-02,\n",
      "        -2.31032118e-01, -5.22745396e-02,  5.51891475e-02,\n",
      "        -2.25056970e-02, -2.11318649e-01,  2.51666170e-06,\n",
      "         1.07207902e-02,  3.79731884e-01, -4.06539303e-07,\n",
      "         3.11639169e-01,  1.03753413e-01,  2.25428199e-05,\n",
      "        -2.68802586e-01, -1.50449692e-01, -4.06027635e-01,\n",
      "         8.47990383e-02,  1.48682225e-01,  6.05657582e-02,\n",
      "         1.68539935e-01,  5.27895040e-02,  2.92177120e-07,\n",
      "         7.88767693e-07,  1.54891902e-02, -3.69100723e-03,\n",
      "        -2.41429846e-01, -2.17476957e-02, -8.29574692e-02,\n",
      "        -2.56217342e-01, -1.91024252e-01, -2.10309748e-02,\n",
      "        -1.99213368e-05,  2.09513767e-08,  2.13104646e-01,\n",
      "         2.71032281e-01,  2.24090331e-05,  1.02785274e-01,\n",
      "        -4.36136671e-02],\n",
      "       [-1.80564553e-01,  3.20578303e-01,  1.93792081e-05,\n",
      "        -6.76844665e-03, -3.01866745e-01, -1.59009049e-02,\n",
      "         1.09713596e-01,  3.91823850e-01,  9.81086374e-02,\n",
      "        -3.13136566e-01,  4.37033423e-01, -2.51017358e-05,\n",
      "         2.22660126e-01,  1.39234777e-01,  3.77953100e-01,\n",
      "         3.51470238e-01, -4.79725517e-02,  3.83882452e-01,\n",
      "         7.65673587e-02, -8.04219390e-02, -1.74155583e-02,\n",
      "        -1.70457961e-01,  2.49958528e-02,  3.00649890e-01,\n",
      "        -2.09387037e-01,  3.42085077e-01, -1.81690438e-02,\n",
      "         1.06727720e-05, -2.57302698e-02,  3.25836926e-01,\n",
      "         1.67752124e-01, -3.47620942e-02,  1.96187565e-01,\n",
      "         4.96316465e-02, -6.21447097e-03,  3.07876238e-07,\n",
      "         4.52521546e-02, -1.84677392e-02,  1.14691837e-01,\n",
      "         3.28948609e-01,  2.93602967e-01,  3.36814059e-01,\n",
      "        -4.47488012e-05,  3.63274099e-02,  5.41188959e-05,\n",
      "        -7.49819970e-04,  3.68571213e-06, -4.10840157e-02,\n",
      "        -2.84851410e-02, -6.75349784e-07,  3.08401079e-01,\n",
      "        -7.96055047e-04, -2.25543021e-03,  3.59220639e-01,\n",
      "         6.26788000e-03, -7.21349699e-02, -5.54860186e-05,\n",
      "         3.30202218e-01, -3.93908467e-01, -5.73791319e-03,\n",
      "         5.89801991e-03,  9.30178617e-02, -1.63410167e-07,\n",
      "        -2.31349159e-01,  1.54744647e-01,  4.54650454e-02,\n",
      "         1.35335000e-01, -1.82528434e-01, -3.82828756e-06,\n",
      "        -5.42063826e-02, -6.59099210e-02, -3.80907510e-02,\n",
      "         1.06007644e-01, -1.15718450e-01, -4.28670985e-04,\n",
      "        -2.68740060e-01, -3.21921926e-01, -2.36391625e-01,\n",
      "         3.26924430e-03,  2.75449741e-01,  1.22723790e-01,\n",
      "         2.51992717e-01,  4.10092195e-01,  5.80394232e-07,\n",
      "        -1.06436886e-06,  1.51928434e-06,  5.47625798e-06,\n",
      "        -1.42617987e-01, -3.21867369e-02, -9.47314026e-03,\n",
      "        -3.40452629e-01, -1.02314397e-02,  3.72787927e-02,\n",
      "        -5.54452533e-06, -2.10353799e-02,  8.10174747e-02,\n",
      "         3.55204344e-01, -1.36827426e-07,  7.64799643e-02,\n",
      "         1.55351391e-01]]), array([[-6.86269291e-02],\n",
      "       [ 1.94096289e-01],\n",
      "       [-2.64867099e-02],\n",
      "       [-2.01491835e-01],\n",
      "       [-2.74519654e-01],\n",
      "       [ 2.34667401e-01],\n",
      "       [ 2.58154788e-02],\n",
      "       [ 1.92640800e-01],\n",
      "       [ 2.98087600e-01],\n",
      "       [-4.00405833e-01],\n",
      "       [ 1.15326648e-01],\n",
      "       [-1.69286104e-03],\n",
      "       [ 2.66159542e-01],\n",
      "       [-1.28902770e-01],\n",
      "       [ 1.46962171e-01],\n",
      "       [ 2.63358960e-01],\n",
      "       [ 4.48018876e-02],\n",
      "       [ 2.90086955e-01],\n",
      "       [-9.44924759e-02],\n",
      "       [ 6.93456421e-02],\n",
      "       [ 3.02531225e-02],\n",
      "       [-1.73968581e-01],\n",
      "       [-1.27307042e-01],\n",
      "       [ 2.81785122e-01],\n",
      "       [-1.53063599e-01],\n",
      "       [ 2.26099334e-01],\n",
      "       [ 1.19588976e-06],\n",
      "       [-6.35279552e-02],\n",
      "       [-6.34760847e-03],\n",
      "       [ 3.31015710e-01],\n",
      "       [-1.18292296e-01],\n",
      "       [ 7.97666958e-03],\n",
      "       [ 4.24321838e-01],\n",
      "       [-5.18618485e-02],\n",
      "       [ 2.14427522e-01],\n",
      "       [ 2.05712294e-02],\n",
      "       [-6.50986916e-02],\n",
      "       [ 2.05063931e-01],\n",
      "       [-9.08723574e-02],\n",
      "       [ 3.74014053e-01],\n",
      "       [ 3.98976483e-01],\n",
      "       [ 2.72074170e-01],\n",
      "       [ 3.18843214e-06],\n",
      "       [-1.50059887e-01],\n",
      "       [ 8.15544953e-02],\n",
      "       [-3.29004429e-02],\n",
      "       [-3.81835459e-04],\n",
      "       [-5.71385115e-02],\n",
      "       [ 1.86217161e-01],\n",
      "       [ 6.57831092e-02],\n",
      "       [ 3.06048440e-01],\n",
      "       [ 2.96689341e-01],\n",
      "       [-3.92423955e-02],\n",
      "       [ 2.94540453e-01],\n",
      "       [-1.70121566e-01],\n",
      "       [-7.46153241e-02],\n",
      "       [-2.39066752e-06],\n",
      "       [ 2.48193842e-01],\n",
      "       [-3.10600636e-01],\n",
      "       [-1.28255072e-01],\n",
      "       [-2.22579311e-01],\n",
      "       [-1.90964655e-01],\n",
      "       [ 1.98134283e-06],\n",
      "       [-4.73596641e-01],\n",
      "       [-3.93749325e-02],\n",
      "       [-5.42675327e-02],\n",
      "       [ 4.13599652e-02],\n",
      "       [-1.74837894e-01],\n",
      "       [ 1.26026749e-01],\n",
      "       [-1.26286786e-05],\n",
      "       [ 3.32730182e-01],\n",
      "       [-4.14016287e-02],\n",
      "       [ 2.05262465e-01],\n",
      "       [-1.66037279e-01],\n",
      "       [-6.46550015e-02],\n",
      "       [-3.68292339e-01],\n",
      "       [-3.47172271e-01],\n",
      "       [-2.97679820e-01],\n",
      "       [-1.67936755e-01],\n",
      "       [ 2.63399099e-01],\n",
      "       [-9.48634930e-02],\n",
      "       [ 1.52506188e-01],\n",
      "       [ 4.54688759e-01],\n",
      "       [-1.69809965e-02],\n",
      "       [ 4.16189047e-02],\n",
      "       [-1.35222004e-05],\n",
      "       [ 9.75331010e-03],\n",
      "       [-2.99790438e-01],\n",
      "       [-6.27638169e-04],\n",
      "       [ 2.01875969e-02],\n",
      "       [-2.05220476e-01],\n",
      "       [-2.71200218e-01],\n",
      "       [-9.80657684e-02],\n",
      "       [-6.22991844e-02],\n",
      "       [ 3.11937894e-04],\n",
      "       [ 3.18399373e-01],\n",
      "       [ 1.15245682e-01],\n",
      "       [-7.43836591e-02],\n",
      "       [ 1.51647209e-01],\n",
      "       [-1.35908048e-02]])]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/hhk/anaconda3/lib/python3.7/site-packages/sklearn/neural_network/multilayer_perceptron.py:566: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n"
     ]
    }
   ],
   "source": [
    "\n",
    "mlp = MLPClassifier() # set the method\n",
    "mlp.fit(X_training, y_training)                    # training\n",
    "y_pred=mlp.predict(X_training)                      # prediction\n",
    "print(y_pred)                                      # show the output\n",
    "print([coef.shape for coef in mlp.coefs_])  # size of synapsis weights\n",
    "print(mlp.coefs_)                                 # synapsis weights\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Now your Turn!\n",
    "### Experiments\n",
    "\n",
    "-  Change the data (X_training, y_training, X_testing)\n",
    "-  Change the hidden layer of MLP: number of layers (int) or size (n,m)\n",
    "-  Change activation function of MLP: {'identity', 'logistic',...}\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/hhk/anaconda3/lib/python3.7/site-packages/sklearn/neural_network/multilayer_perceptron.py:566: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "MLPClassifier(activation='logistic', alpha=0.0001, batch_size='auto',\n",
       "              beta_1=0.9, beta_2=0.999, early_stopping=False, epsilon=1e-08,\n",
       "              hidden_layer_sizes=(100,), learning_rate='constant',\n",
       "              learning_rate_init=0.001, max_iter=200, momentum=0.9,\n",
       "              n_iter_no_change=10, nesterovs_momentum=True, power_t=0.5,\n",
       "              random_state=None, shuffle=True, solver='adam', tol=0.0001,\n",
       "              validation_fraction=0.1, verbose=False, warm_start=False)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.linear_model import Perceptron\n",
    "import sklearn.metrics as metric\n",
    "import numpy as np\n",
    "\n",
    "X_training=[[1, 1], \n",
    "            [1, 0],\n",
    "            [0, 1],\n",
    "            [0, 0]\n",
    "           ]\n",
    "y_training=[1, \n",
    "            1,\n",
    "            1,\n",
    "            0\n",
    "           ]\n",
    "\n",
    "\n",
    "# mlp = MLPClassifier()\n",
    "# mlp.fit(X_training,y_training)\n",
    "\n",
    "mlp = MLPClassifier(activation = 'logistic')\n",
    "mlp.fit(X_training,y_training)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### XNOR \n",
    "Try solve the following Boolean Exclusive Not Or (XNOR) problem. How to improve the accuracy? How many minimum hidden layer is needed to make it 100% accurate?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_training=[[1, 1], \n",
    "            [1, 0],\n",
    "            [0, 1],\n",
    "            [0, 0]\n",
    "           ]\n",
    "y_training=[1, \n",
    "            0,\n",
    "            0,\n",
    "            0\n",
    "           ]\n",
    "X_testing=X_training\n",
    "y_true=y_training\n",
    "        \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data from File"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "species_virginica\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/hhk/anaconda3/lib/python3.7/site-packages/sklearn/neural_network/multilayer_perceptron.py:566: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "1.0"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "train = pd.read_csv(\"iris.csv\")\n",
    "train=pd.get_dummies(train)\n",
    "features = train.columns[:-1]\n",
    "y = train.columns[-1] # y = 'species_virginica'\n",
    "Y =(train[y])\n",
    "X = train[features]\n",
    "X_train, X_test, y_train, y_test = train_test_split(X,Y,test_size=0.5)\n",
    "nn = MLPClassifier()\n",
    "nn.fit(X_train,y_train)\n",
    "nn.score(X_test,y_test)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Your Turn\n",
    "Creat your network based on only two features of the given dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#your answer\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Try to create and train a neural network for a given dataset with higher accuracy!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#your answer\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
